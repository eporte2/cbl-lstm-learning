---
title: "predicting_AoA"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tools)
#library(Hmisc)
library(glue)
library(broom)
#library(broom.mixed)
#library(langcog)
library(stringr)
library(tidyverse)
library(lme4)
library(modelr)
library(purrr)

```

### Get AoA estimates
The following is based on the appendix D from the Wordbank book (Frank et al. 2019).
taken from: https://github.com/langcog/wordbank-book/blob/master/104-appendix-aoa.Rmd 
I use there Bayesian GLM with hand-tuned prior parameters model to get fitted AoA estimates on the English Words & Sentences data from Wordbank. (I take their data and model as is.)
```{r aoa_estimates}
load("../../../data/aoa_predictors/eng_ws_raw_data.Rds")

ms <- eng_ws %>%
  group_by(definition, age, category) %>%
  summarise(prop = mean(value == "produces", na.rm = TRUE), 
            num_true = sum(value == "produces", na.rm = TRUE), 
            num_false = sum(value != "produces", na.rm = TRUE), 
            n = sum(c(num_true, num_false))) %>%
  filter(!is.na(category))

fit_bglm <- function(data) {
  model <- arm::bayesglm(cbind(num_true, num_false) ~ age, 
                         family = "binomial", 
                         prior.mean = .3,
                         prior.scale = c(.01),
                         prior.mean.for.intercept = 0,
                         prior.scale.for.intercept = 2.5,
                         prior.df = 1,
                         data = data)
  aoa <- -model$coefficients[["(Intercept)"]] / model$coefficients[["age"]]
  
  tibble(definition = data$definition[1],
         category = data$category[1],
         bglm_slope = model$coefficients[["age"]],
         bglm_aoa = aoa)
}

bglm_aoas <- ms %>%
  split(.$definition) %>%
  map(fit_bglm) %>%
  bind_rows

```

### Get scaled predictors from Braginsky et al. (2019) and scaled surprisals

```{r get_predictors}
## Data of avg_freq
load("../../../data/aoa_predictors/avg_freq.RData")

## Data from Braginsky et al. (2019)
load("../../../data/aoa_predictors/model_data.RData")
load("../../../data/aoa_predictors/uni_joined.RData")
uni_joined_eng <- uni_joined %>% filter(language == "English (American)")


## get surprisal results from all LSTM models
my_get_transcript_results <- function(file){
  df = read.csv(file)
  #Extract child name from file name and add variable.
  file_name = strsplit(file_path_sans_ext(file), "/")[[1]]
  file_name = file_name[(length(file_name))]
  child_name = strsplit(file_name,".aoa_result", fixed=TRUE)[[1]]
  df = df %>%
    mutate(child_name = child_name)
  return(df)
}

my_get_prod_results <- function(result_dir){
  files = list.files(path=result_dir, pattern="*.csv", full.names=TRUE, recursive=FALSE)
  df.prod_results = files %>% map(my_get_transcript_results) %>% reduce(rbind)
  return(df.prod_results)
}

result_dir = "../../../data/results/aoa_surprisals/"
model_surprisals = my_get_prod_results(result_dir)
### removing Thomas, because many surprisals were "Inf" which results in errors
model_surprisals = model_surprisals %>% filter(child_name!="Thomas")

average_child_surprisals = model_surprisals %>% 
  group_by(word, uni_lemma) %>% 
  mutate(child_name = "Average_child") %>% 
  mutate(avg_surprisal = mean(avg_surprisal, na.rm=TRUE)) %>% 
  ungroup() %>% 
  unique()


model_surprisals = average_child_surprisals

surp_model_data <- model_surprisals %>% left_join(avg_freq) %>% 
  select(uni_lemma, avg_surprisal, avg_freq, child_name) %>% 
  mutate(uni_lemma = as.character(uni_lemma)) %>% 
  left_join(ungroup(model_data)) %>% 
  group_by(child_name) %>%
  # mutate_at(vars(!!predictors), funs(as.numeric(scale(.)))) %>%
  nest()

predictors <- c("avg_surprisal", "avg_freq", "frequency", "MLU", "final_frequency", "solo_frequency", "num_phons", "concreteness", "valence", "arousal", "babiness")

pred_sources <- list(
  c("avg_surprisal", "avg_freq"),
  c("frequency", "MLU", "final_frequency", "solo_frequency"),
  c("valence", "arousal"),
  "concreteness", "babiness", "num_phons"
)

fit_predictor <- function(pred, d) {
  xs <- pred_sources %>% discard(~pred %in% .x) %>% unlist()
  x_str <- xs %>% paste(collapse = " + ")
  lm(as.formula(glue("{pred} ~ {x_str}")), data = d) %>%
    augment(newdata = d) %>%
    select(uni_lemma, lexical_category, .fitted)
}

max_steps <- 20
iterate_predictors <- function(lang_data) {
  missing <- lang_data %>%
    gather(predictor, value, !!predictors) %>%
    mutate(missing = is.na(value)) %>%
    select(-value) %>%
    spread(predictor, missing)
  predictor_order <- lang_data %>%
    gather(predictor, value, !!predictors) %>%
    group_by(predictor) %>%
    summarise(num_na = sum(is.na(value))) %>%
    filter(num_na != 0) %>%
    arrange(num_na) %>%
    pull(predictor)
  imputation_data <- lang_data %>%
    mutate_at(vars(!!predictors),
              funs(as.numeric(Hmisc::impute(., fun = "random"))))
  for (i in 0:max_steps) {
    pred <- predictor_order[(i %% length(predictor_order)) + 1]
    imputation_fits <- fit_predictor(pred, imputation_data)
    imputation_data <- missing %>%
      select(uni_lemma, lexical_category, !!pred) %>%
      rename(missing = !!pred) %>%
      right_join(imputation_data) %>%
      left_join(imputation_fits) %>%
      mutate_at(vars(pred), funs(if_else(is.na(missing), .fitted, .))) %>%
      select(-.fitted, -missing)
  }
  return(imputation_data)
}

model_data_imputed <- surp_model_data %>%
  mutate(imputed = map(data, iterate_predictors)) 

all_predictors_data <- model_data_imputed %>%
  select(-data) %>%
  unnest() %>%
  group_by(child_name) %>%
  mutate_at(vars(predictors), funs(as.numeric(scale(.))))

save(model_data_imputed, file = "../../../data/aoa_predictors/model_data_imputed_avg_child.RData")
save(all_predictors_data, file = "../../../data/aoa_predictors/all_predictors_data_avg_child.RData")

```

Join AoA estimates (dependent variable) to predictors together
```{r join_data}

aoa_estimates <- bglm_aoas %>% 
  mutate(words = tolower(definition),
         aoa = bglm_aoa) %>% 
  select(words, aoa)

#aoa_estimates <- empirical_aoas %>% 
#  mutate(words = tolower(definition),
#         aoa = empirical_aoa) %>% 
#  select(words, aoa)

data <- all_predictors_data %>% 
  left_join(aoa_estimates) %>% 
  filter(!is.na(aoa)) %>% 
  filter(lexical_category != "other") %>% ungroup()
  
  mutate(lexical_category = lexical_category %>% fct_relevel("other")) %>% 
  ungroup()

```

All the models to fit 

```{r formulae}
#full_surp = ~ lexical_category * avg_surprisal + lexical_category * frequency + lexical_category * MLU + lexical_category * final_frequency + lexical_category * solo_frequency + lexical_category * num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness

full_surp = ~ lexical_category * avg_surprisal + lexical_category * avg_freq + lexical_category * num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness

freq_surp = ~ lexical_category * avg_freq + lexical_category * avg_surprisal

#full_set = ~ lexical_category * frequency + lexical_category * MLU + lexical_category * final_frequency + lexical_category * solo_frequency + lexical_category *  num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness

full_set = ~ lexical_category * avg_freq + lexical_category *  num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness

freq_only = ~ lexical_category * avg_freq

#full_surp_only = ~ lexical_category * avg_surprisal + lexical_category * MLU + lexical_category * final_frequency + lexical_category * solo_frequency + lexical_category * num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness

full_surp_only = ~ lexical_category * avg_surprisal + lexical_category * num_phons + lexical_category * concreteness + lexical_category * valence + lexical_category * arousal + lexical_category * babiness


surp_only = ~ lexical_category * avg_surprisal

null_model = ~ 1

formulae <- formulas(~aoa, null_model, full_set, freq_only, full_surp, freq_surp, surp_only, full_surp_only)


```

Run cross validation for all models
```{r cv}

loo_data <- crossv_loo(ungroup(data))
  
fit_models <- function(id) {
  models <- "no model"
  #print("run model")
  train_idx <- loo_data[id,1][[1]][[1]]$idx
  test_idx <- loo_data[id,2][[1]][[1]]$idx
  train_data <- data[train_idx,]
  try(models <- fit_with(train_data, lm, formulae))
  
  result <- enframe(models) %>% 
    mutate(model = value,
      train = list(train_idx),
    test = list(test_idx)) %>% 
    select(-c(value))
  
  return(result)
  
}


models_loo<- loo_data$.id %>% map( ~ fit_models(.)) %>% reduce(rbind)
#Remove failed models

#mse_calc <- function(n){
#  test_data = data[loo_data$test[[n]],]
#  Y = test_data$aoa
#  Y_pred = predict(models_kfold$models[[n]],  test_data)
#  mse_ = mean((Y - Y_pred)^2)
#  return(as.numeric(mse_))
#}

#dev_calc <- function(id, model){
#  test_data = data[id,]
#  Y = test_data$aoa
#  Y_pred = predict(model,  test_data)
#  dev_ = abs(Y - Y_pred)
#  return(dev_)
#}

get_aoa_pred<- function(n){
   row <- tibble(
     name = models_loo$name[n],
     test = models_loo$test[n],
     train = models_loo$train[n],
     model = models_loo$model[n],
     test_word = data$words[as.numeric(test)],
     lexical_category = data$lexical_category[as.numeric(test)],
    aoa = data$aoa[as.numeric(test)],
    aoa_pred = predict(model[[1]],  data[as.numeric(test),]))
  return(row)
}

#models_kfold_try <- sep_models_kfold  %>% gather( key= model_name, value = "models", full_set, freq_only, full_surp, freq_surp, surp_only, full_surp_only)

sep_models_loo <- map(c(1:nrow(models_loo)), get_aoa_pred) %>% bind_rows() %>% 
  mutate(abs_dev = abs(aoa - aoa_pred)) %>% 
  mutate(se = abs_dev^2)


results <- sep_models_loo %>% 
  transform(abs_dev = as.numeric(abs_dev)) %>% 
  group_by(name) %>%
  summarise(mean_abs_dev = mean(abs_dev), rmse = sqrt(mean(se)), mse = mean(se))

  
```


Compare model performance by word
```{r byword}
test <- sep_models_loo %>% filter(name %in% c("full_set", "full_surp_only")) %>% 
  group_by(name, test_word, lexical_category) %>% summarise(mean(abs_dev)) %>% 
  spread(key=name, value="mean(abs_dev)" ) %>% 
  mutate(diff = full_set-full_surp_only) %>% 
  arrange(desc(diff))


test <- sep_models_loo %>% filter(name %in% c("freq_only", "surp_only")) %>% 
  group_by(name, test_word, lexical_category) %>% summarise(mean(abs_dev)) %>% 
  spread(key=name, value="mean(abs_dev)" ) %>% 
  mutate(diff = freq_only-surp_only) %>% 
  arrange(desc(diff))

plot_data = test
p = ggplot(data = plot_data %>% arrange(desc(diff)) %>% head(50), 
            aes(x = reorder(test_word,diff), y = diff, fill=lexical_category)) +
  geom_bar(stat='identity') +
  coord_flip()+
  scale_fill_discrete(name = "Lexical category", labels = c("nouns", "function words", "predicates"))+
  theme(text = element_text(size=18))+
  labs(x="word", y="difference in absolute deviation")

ggsave("_diff_byword_top50.png",plot=p, width = 7, height = 8, units="in", limitsize = FALSE)

plot_data %>% group_by(lexical_category) %>% count()
plot_data %>% arrange(desc(diff)) %>% head(100) %>% group_by(lexical_category) %>% count()


```




View models trained on all data
```{r all_data_models}
all_data_models <- fit_with(data, lm, formulae)
plot(predict(all_data_models$null_model), data$aoa)
summary(all_data_models$full_surp_only)
```

Error analysis by word 
```{r by_word}
### error analysis by words
model_names = c("null_model","full_set", "freq_only", "full_surp", "freq_surp", "surp_only", "full_surp_only")

error_analysis_byword <- function(n){
  model = all_data_models[[n]]
  mse_byword_results = data %>% 
    ungroup() %>% 
    mutate(predicted_aoa = predict(model),
           model_name = model_names[[n]]) %>% 
    group_by(words) %>% 
    mutate(mse_ = mean((aoa - predicted_aoa)^2)) %>% 
    select(model_name, words, mse_, lexical_category)
  
  return(mse_byword_results)
}

errs_produces_byword_all_data<- map(c(1:7), error_analysis_byword) %>% reduce(rbind) 


words_lexcat_mse <- errs_produces_byword_all_data %>% 
  filter(model_name %in% c("full_set", "full_surp_only")) %>% ungroup() %>% 
  spread(key=model_name, value=mse_) %>% 
  mutate(diff = full_set - full_surp_only) %>% 
  arrange(desc(diff))

plot_data = 
p = ggplot(data = plot_data %>% arrange(desc(diff)) %>% head(50), 
            aes(x = reorder(words,diff), y = diff, fill=lexical_category)) +
  geom_bar(stat='identity') +
  coord_flip()+
  scale_fill_discrete(name = "Lexical category", labels = c("unmarked", "nouns", "function words", "predicates"))+
  theme(text = element_text(size=18))+
  labs(x="word", y="difference in MSE")


words_lexcat_mse %>% group_by(lexical_category) %>% count()
 words_lexcat_mse %>% arrange(desc(diff)) %>% head(100) %>% group_by(lexical_category) %>% count()

 
ggplot(data, aes(x=aoa, y=avg_surprisal, color=lexical_category))+geom_point()

```